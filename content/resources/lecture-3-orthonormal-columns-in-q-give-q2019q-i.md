---
content_type: resource
description: ''
end_time: ''
file: null
learning_resource_types:
- Lecture Videos
license: https://creativecommons.org/licenses/by-nc-sa/4.0/
ocw_type: ''
optional_tab_title: Problem Sets
optional_text: "**Problems for Lecture 3  \nFrom textbook Section I.5**\n\n2\\. Draw\
  \ unit vectors _**u**_ and _**v**_ that are _not_ orthogonal. Show that _**w**_\
  \ = _**v**_ - _**u**_(_**u**_{{< sup \"T\" >}}_**v**_) is orthogonal to _**u**_\
  \ (and add **_w_** to your picture).\n\n4\\. Key property of every orthogonal matrix:\
  \ ||_Q_**_x_**||{{< sup \"2\" >}} = ||**_x_**||{{< sup \"2\" >}} for every vector\
  \ **_x_**. More than this, show that (_Q_**_x_**){{< sup \"T\" >}}(_Q_**_y_**)=\
  \ **_x_**{{< sup \"T\" >}}**_y_** for every vector **_x_** and **_y_**. So _lengths\
  \ and angles are not changed by Q_. **Computations with _Q_ never overflow!**\n\n\
  6\\. A **permutation matrix** has the same columns as the identity matrix (in some\
  \ order). _Explain why this permutation matrix and every permutation matrix is orthogonal_\
  \ :  \n  \n_P_ = \\\\(\\\\left\\[\\\\begin{array}{@{\\\\,}rrrr@{\\\\,}}0&1&0&0\\\
  \\\\\\0&0&1&0\\\\\\\\0&0&0&1\\\\\\\\1&0&0&0\\\\\\\\\\\\end{array}\\\\right\\]\\\\\
  ) has orthonormal columns so _P_{{< sup \"T\" >}}_P_ = \\_\\_\\_ and _P_{{< sup\
  \ \"\u22121\" >}}\\= \\_\\_\\_.  \n  \nWhen a matrix is symmetric or orthogonal,\
  \ **it will have orthogonal eigenvectors**. This is the most important source of\
  \ orthogonal vectors in applied mathematics."
parent_title: Video Lectures
parent_type: CourseSection
related_resources_text: ''
resource_index_text: ''
resourcetype: Video
start_time: ''
title: "Lecture 3: Orthonormal Columns in Q Give Q\u2019Q = I "
uid: 35e13b17-714e-fc16-c248-7c9d6fdb8f0c
video_files:
  archive_url: https://archive.org/download/MIT18.065S18/MIT18_065S18_Lecture03_300k.mp4
  video_captions_file: /courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/3fe002ea6600581bb8152fbb5b3f7b06_Xa2jPbURTjQ.vtt
  video_thumbnail_file: https://img.youtube.com/vi/Xa2jPbURTjQ/default.jpg
  video_transcript_file: /courses/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/d843ac96819a148f6afefc70cf98d5d9_Xa2jPbURTjQ.pdf
video_metadata:
  youtube_id: Xa2jPbURTjQ
---

Description
-----------

This lecture focuses on orthogonal matrices and subspaces. Professor Strang reviews the four fundamental subspaces: column space C(A), row space C(A{{< sup "T" >}}), nullspace N(A), left nullspace N(A{{< sup "T" >}}).

Summary
-------

Examples:

*   Rotations
*   Reflections
*   Hadamard matrices
*   Haar wavelets
*   Discrete Fourier Transform (DFT)
*   Complex inner product

Related section in textbook: I.5

**Instructor:** Prof. Gilbert Strang

